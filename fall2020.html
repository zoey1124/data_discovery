<html>
    <head>
        <title>Data Discovery</title>
        
        <style>
            body {
                font-family:'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unicode', Geneva, Verdana, sans-serif;
                margin: 0;
                padding: 0;
                animation: fadeInAnimation ease 3s;
                animation-iteration-count: 1;
                animation-fill-mode: forwards;
            }
            @keyframes fadeInAnimation {
            0% {
                opacity: 0;
            }
            100% {
                opacity: 1;
            }
            }
            html {
                scroll-behavior: smooth;
            }
            a {
                text-decoration: none;
            }
            a:visited {
                color:black;
            }
            a:link {
                color: black;
            }
            .desktop {
                cursor: pointer;
                display: inline-block;
                /* top right bottom left */
                padding: 20px 20px 20px 40px;
                transition: 0.3s;
            }
            #desktop:hover {
                background-color: rgba(119, 97, 76, 0.536); /* Add a dark-grey background on hover */
                color: white;
            }
            .bgimg {
                background: url(cover.JPEG);
                background-position: center;
                background-size: cover;
                color: #ffffff;
                height: 80%;
                position: relative;
                text-align: center; 
            }
            header {
                font-weight: 600;
                font-size: 32px;
                letter-spacing: 8px;
                padding: 170px 20px 20px 20px;
            }
            h2 {
                letter-spacing: 2px;
                font-size: 26px;
            }
            p {
                line-height: 30px;
            }
            .bgimg > p {
                padding: 0px 50px 0px 50px;
            }
            .words {
                /* top right bottom left */
                padding: 0px 100px 20px 100px;
            }
            .fall2020 {
                /* top right bottom left */
                padding: 0px 50px 0px 50px;
                font-weight: 800;
                cursor: pointer;
            }
            .titles{
                padding-left: 50px;
                padding-top: 10px;
            }
            .Introduction, .Annotation, .Team {
                padding: 20px 40px 40px 60px;
            }
            .Introduction {
                background-color: rgb(79, 57, 36);
                color: white;
            }
            .Data, .Result, .Contact{
                background-color: rgba(255, 246, 230, 0.479);
                padding: 20px 40px 20px 60px; 
            }
            .data-pic-container {
                display: inline-grid;
                grid-template-columns: 30% 30%;
                grid-row: auto auto;
                grid-column-gap: 50px;
                grid-row-gap: 30px;
                justify-content: center;
                grid-template-rows: 300px 300px;
                width: 90%;
            }
            .spec-container {
                position: relative;
                margin-left: 7%;
            }
            .spec-container .after {
                position: absolute;
                top: 0;
                left: 0;
                width: 100%;
                height: 100%;
                transition: opacity 0.5s ease-in-out 0s;
                opacity: 0;
                color: #FFF;
                text-align: center; 
                background: rgba(255, 255, 255, 0.797);
            }
            .spec-container:hover .after {
                opacity: 0.95;
                display: block;
            }
            .spec-container > .after > .text {
                position: relative;
                top: 40%;
                font-size: 18px;
                color: black;
                margin: 0 30px 0 30px; /* top right bottom left */
            }
            .Result > .progress-container {
                display: inline-grid;
                grid-template-columns: 45% 45%;
                grid-row: auto auto;
                grid-column-gap: 9px;
                grid-row-gap: 20px;
                justify-content: center;
                grid-template-rows: 300px 300px;
                width: 90%;
            }
            img.pic {
                height: 100%;
                width: 100%;
                box-shadow: 5px 5px 5px grey;
            }
            img.ann-pic {
                height: 60%;
                width: 50%;
                box-shadow: 5px 5px 5px grey;
                margin-left: 20%;
            }
            .Team > .grid-container {
                display: inline-grid;
                grid-template-columns: 20% 20% 20% 20% 20%;
                grid-row: auto auto;
                grid-column-gap: 90px;
                grid-row-gap: 50px;
                margin-left: 5%;
                width: 60%;
            }
            .name {
                margin-left: 5px;
            }
            .item {
                border-radius: 16%;
                display:flex;
            }

            #myBtn {
                display: none; /* Hidden by default */
                position: fixed; /* Fixed/sticky position */
                bottom: 20px; /* Place the button at the bottom of the page */
                right: 30px; /* Place the button 30px from the right */
                z-index: 99; /* Make sure it does not overlap */
                border: none; /* Remove borders */
                outline: none; /* Remove outline */
                background-color: rgb(184, 149, 118); /* Set a background color */
                color: rgb(1, 0, 0); /* Text color */
                opacity: 70%;
                cursor: pointer; /* Add a mouse pointer on hover */
                padding: 15px; /* Some padding */
                border-radius: 50%; /* Rounded corners */
                font-size: 18px; /* Increase font size */
            }

            #myBtn:hover {
                background-color: rgb(79, 57, 36); /* Add a dark-grey background on hover */
                color: white;
            }
            footer {
                margin-top: 200px;
            }
        </style>
    </head>
 
    <body>
        <div class="menu">
            <div class="desktop" id="desktop"><a href="index.html">Home</a></div>
            <div class="desktop" id="desktop"><a href="#Data">Data Collection</a></div>
            <div class="desktop" id="desktop"><a href="#Annotation">Annotation</a></div>
            <div class="desktop" id="desktop"><a href="#Result">Results</a></div>
            </div>
        </div>

        <a name="Introduction">
            <div class="Introduction">
                <div class="titles">
                    <h2> An early warning system for public safety and the recognition of emotions</h2>
                </div>
                <div class="words">
                    <p>
                    Human beings have a rather unique ability to discern the emotional states of one another via their unconscious perception, processing, and identification of the specific acoustic features associated with particular emotions. 
                    <br><br/>This is especially true in the case of emotional states that are rooted in aggression. We know this to be the case because similar suggestions have been made by the likes of Klaus Scherer who suggested that emotional states like fear and anger could be associated with a higher vocal pitch due to high levels of epinephrine in the body that cause the vocal cords to tremble. 
                    <br><br/>Thus, Scherer observed that the trembling of the vocal cords produced a higher pitch than was typical of speech generated in a state of rest or non-arousal. Scherer’s findings led to the basis of computationally understood and discerned emotion being measured and perceived on a basis of “valence and arousal”; Our findings aim to set a new paradigm for the computational understanding of emotion.  
                    <br><br/>This project aimed to identify the acoustic features associated with aggression in police officers and citizens and determine whether one could use vocal cues to predict violent behavior, on the part of the officers towards citizens. In essence, we wanted to prove that the voice can be used as a tool to predict human behavior in order to find and potentially prevent situations of police brutality. 
                    </p>
                </div>
            </div>
        </a>

        <a name="Data">
            <div class="Data">
                <div class="titles">
                    <h2>Data Collection</h2>
                </div>
                <div class="words">
                <p>
                For this project, we collected video clips of police-citizen interactions from YouTube. Each video was required to:
                <br><br/>- Contain an interaction between a police officer and citizen
                <br><br/>- Contain dialogue (from either the police officer or citizen, not a third party)
                <br><br/>To do this, we scraped video URLs of police interactions (primarily police body cam videos) from YouTube. We then implemented a script that identified dialogue within each video by utilizing their associated auto generated captions and split the videos into 1 - 5 seconds segments. Each of these clips was stored in a Microsoft Azure Blob Storage instance. We acknowledge that since we relied on YouTube data as our source of police/citizen interactions, there may be sample bias. 
                Here is our dataset analysis.
                </p>  
                </div> 
                
                <div class="data-pic-container">
                    <div><img class="pic" src="falldemo/cit-eth.png" height="10", width="10"></div>
                    <div><img class="pic" src="falldemo/pol-eth.png" height="10", width="10"></div>
                    <div><img class="pic" src="falldemo/cit-gen.png" height="10", width="10"></div>
                    <div><img class="pic" src="falldemo/pol-gen.png" height="10", width="10"></div>
                </div>
            </div>
        </a>

        <a name="Annotation">
            <div class="Annotation">
                <div class="titles">
                    <h2>Annotation</h2>
                </div>
                <div class="words">
                    <p>Apart from acoustic features which were extracted automatically, we annotated each clip for physical elements including the officer and citizen’s weapon use, race, gender, camera use, dialogue (in text), emotionality and aggression. In order to standardize the subjective features, aggression and emotionality, we developed a scale for each. For emotionality, we relied on a bipolar scale; the sign of the number indicates the type of emotion, positive or negative, and the magnitude represents how consciously expressive the individual is of the emotion. For aggression, we relied on Yudofsky’s Overt Aggression Scale (OAS), commonly used in clinical psychology. To streamline this process we developed a user interface (using Streamlit) that displayed the video associated with each clip. 
                    </p>
                </div>

                <div class="ann-container">
                    <img class="ann-pic" src="annotation.png" height="10", width="10">
                </div>

            </div>
        </a>

        <a name="Result">
            <div class="Result">
                <div class="titles">
                    <h2>Results</h2>
                </div>
                <div class="words">
                <p>
                With annotated data, we analyzed each of the audio segments using Soundsig, an open-source API that extracts features such as fund, kurtosis time, and entropy time from audios. 
                Shown below are visualizations of the performed spectral analysis. Given the high-dimensionality of our data we relied on one-way anova, PCA and k-fold cross validation to extract statistically significant features. 
                </div>

                <div class="progress-container">
                    <div class="spec-container">
                        <div><img class="pic" src="falldemo/spec.png" height="10", width="10"></div>
                        <div class="after">
                            <div class="text">
                                Generates a MEL spectrogram from the given audio data.<br>
                            </div>
                        </div>
                    </div>

                    <div class="spec-container">
                        <div><img class="pic" src="falldemo/freq.png" height="10", width="14"></div>
                        <div class="after">
                            <div class="text">Transform sound to a log scale of frequency.</div>
                        </div>
                    </div>
                    <div class="spec-container">
                        <div><img class="pic" src="falldemo/randomforest.png" height="10", width="14"></div>
                        <div class="after">
                            <div class="text">Compared with Decision Tree mode, 
                                we find that random forest can achieve higher accuracy on test data. 
                                Important features include max amplitude, rms, and saliency. </div>
                        </div>
                    </div>

                    <div class="spec-container">
                        <div><img class="pic" src="falldemo/agressionRMS.png" height="10", width="14"></div>
                        <div class="after">
                            <div class="text">Data consists of several time series in parallel.</div>
                        </div>
                    </div>

                </div> 
            </div>
        </a>
        <footer>

        </footer>
        <button onclick="topFunction()" id="myBtn" title="Go to top">Top</button> 


        <script>
            //Get the button:
            mybutton = document.getElementById("myBtn");

            // When the user scrolls down 20px from the top of the document, show the button
            window.onscroll = function() {scrollFunction()};

            function scrollFunction() {
                if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
                    mybutton.style.display = "block";
                } else {
                    mybutton.style.display = "none";
                }
            }

            // When the user clicks on the button, scroll to the top of the document
            function topFunction() {
                document.body.scrollTop = 0; // For Safari
                document.documentElement.scrollTop = 0; // For Chrome, Firefox, IE and Opera
            }
        </script>
    </body>
    <script>
    </script>
</html>
